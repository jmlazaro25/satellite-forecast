{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e608107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import skorch\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import Checkpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc73fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file number 0 (GPM_3IMERGDL_2015-01-01.PNG)\n",
      "Processing file number 100 (GPM_3IMERGDL_2015-04-11.PNG)\n",
      "Processing file number 200 (GPM_3IMERGDL_2015-07-20.PNG)\n",
      "Processing file number 300 (GPM_3IMERGDL_2015-10-28.PNG)\n",
      "Processing file number 400 (GPM_3IMERGDL_2016-02-05.PNG)\n",
      "Processing file number 500 (GPM_3IMERGDL_2016-05-15.PNG)\n",
      "Processing file number 600 (GPM_3IMERGDL_2016-08-23.PNG)\n",
      "Processing file number 700 (GPM_3IMERGDL_2016-12-01.PNG)\n",
      "Processing file number 800 (GPM_3IMERGDL_2017-03-11.PNG)\n",
      "Processing file number 900 (GPM_3IMERGDL_2017-06-19.PNG)\n",
      "Processing file number 1000 (GPM_3IMERGDL_2017-09-27.PNG)\n",
      "Processing file number 1100 (GPM_3IMERGDL_2018-01-05.PNG)\n",
      "Processing file number 1200 (GPM_3IMERGDL_2018-04-15.PNG)\n",
      "Processing file number 1300 (GPM_3IMERGDL_2018-07-24.PNG)\n",
      "Processing file number 1400 (GPM_3IMERGDL_2018-11-01.PNG)\n",
      "Processing file number 1500 (GPM_3IMERGDL_2019-02-09.PNG)\n",
      "Processing file number 1600 (GPM_3IMERGDL_2019-05-20.PNG)\n",
      "Processing file number 1700 (GPM_3IMERGDL_2019-08-28.PNG)\n",
      "Processing file number 1800 (GPM_3IMERGDL_2019-12-06.PNG)\n",
      "Processing file number 1900 (GPM_3IMERGDL_2020-03-15.PNG)\n",
      "Processing file number 2000 (GPM_3IMERGDL_2020-06-23.PNG)\n",
      "Processing file number 2100 (GPM_3IMERGDL_2020-10-01.PNG)\n"
     ]
    }
   ],
   "source": [
    "from satforecast.data import data\n",
    "\n",
    "data.download()\n",
    "image_dir = data.process_gs_rainfall_daily(scale=0.1)\n",
    "image_files = data.get_files(image_dir, '*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e824c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3D(nn.Module):\n",
    "    def __init__(self,\n",
    "            seq_len = 5, # Data\n",
    "            image_size = (60, 180),\n",
    "            in_channels = 1, # Conv\n",
    "            conv_channels = 2,\n",
    "            conv_kernals = 3,\n",
    "            conv_stride = 3,\n",
    "            conv_padding = 1,\n",
    "            batch_feats = 10, # BatchNorm\n",
    "            pool_kernals = 2, # Pool\n",
    "            pool_stride = 2,\n",
    "            pool_padding = 1,\n",
    "            linear_feats = None # Linear\n",
    "            ):\n",
    "        super().__init__()\n",
    "        # Swapping (batch_size, seq_len, n_channels, height, width)\n",
    "        # To (batch_size, n_channels, seq_len, height, width)\n",
    "        self.permute_order = (0, 2, 1, 3, 4)\n",
    "\n",
    "        # Convolutional layers\n",
    "        if type(conv_channels) is int:\n",
    "            conv_channels = [conv_channels]\n",
    "\n",
    "        conv_steps = len(conv_channels)\n",
    "\n",
    "        if type(conv_kernals) is int:\n",
    "            conv_kernals = [conv_kernals] * conv_steps\n",
    "            conv_stride = [conv_stride] * conv_steps\n",
    "            conv_padding = [conv_padding] * conv_steps\n",
    "            batch_feats = [batch_feats] * conv_steps\n",
    "\n",
    "        conv_layers = []\n",
    "        for in_c, out_c, c_kern, c_stride, c_pad, b_feats, p_kern, p_stride, p_pad in zip(\n",
    "                [in_channels] + conv_channels[:-1],\n",
    "                conv_channels,\n",
    "                conv_kernals, conv_stride, conv_padding,\n",
    "                batch_feats,\n",
    "                pool_kernals, pool_stride, pool_padding\n",
    "        ):\n",
    "            conv_layers.extend([\n",
    "                nn.Conv3d(in_c, out_c, c_kern, c_stride, c_pad),\n",
    "                nn.BatchNorm3d(b_feats),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool3d(p_kern, p_stride, p_pad)\n",
    "            ])\n",
    "\n",
    "        conv_layers = nn.Sequential(*conv_layers)\n",
    "\n",
    "        # Calculate output shape of convolutional layers\n",
    "        with torch.no_grad():\n",
    "            test_tensor = torch.zeros(1, in_channels, seq_len, image_size[0], image_size[1])\n",
    "            test_tensor = test_tensor.permute(*self.permute_order)\n",
    "            test_output = conv_layers(test_tensor)\n",
    "            conv_output_shape = test_output.shape\n",
    "\n",
    "        # Fully connected layers\n",
    "        if linear_feats is None:\n",
    "            linear_feats = []\n",
    "        elif type(linear_feats) is int:\n",
    "            linear_feats = [linear_feats]\n",
    "\n",
    "        fc_layers = [\n",
    "            np.prod(*conv_output_shape),\n",
    "            *linear_feats,\n",
    "            in_channels * image_size[0] * image_size[1]\n",
    "        ]\n",
    "        for in_feats, out_feats in zip(fc_layers[:-1], fc_layers[1:]):\n",
    "            fc_layers.extend([\n",
    "                nn.Linear(in_feats, out_feats),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ])\n",
    "\n",
    "        self.model = nn.Sequential(*conv_layers, *fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, n_channels, height, width = x.shape\n",
    "        x = x.permute(*self.permute_order)\n",
    "        x = self.model(x)\n",
    "        return x.view(batch_size, n_channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ca125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetRegressor(\n",
    "    CNN3D,\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    lr=0.001,\n",
    "    max_epochs=50,\n",
    "    batch_size=32,\n",
    "    train_split=skorch.dataset.ValidSplit(5),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=[\n",
    "        Checkpoint(dirname='checkpoints', f_params='best_params_cnn3d.pt', monitor='valid_loss_best')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc82b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"\n",
    "class ImageSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(root_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image1_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image2_path = os.path.join(self.root_dir, self.image_files[idx + 1])\n",
    "\n",
    "        image1 = Image.open(image1_path).convert('RGB')\n",
    "        image2 = Image.open(image2_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image2 = self.transform(image2)\n",
    "\n",
    "        return image1, image2\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = ImageSequenceDataset('path/to/dataset', transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41356d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
